{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "from scipy.optimize import *\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import csv\n",
    "from pyproj import CRS, Transformer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import serial\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td\n",
    "import os\n",
    "import pyrebase\n",
    "from sklearn.cluster import DBSCAN\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Declaration\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "# Benjamin's Directory\n",
    "# save_destination = \"C:\\\\Users\\\\Benj\\\\Desktop\\\\LoRa_Rescue\\\\10-23-21_Data\\\\\"\n",
    "# Ianny's Directory\n",
    "save_destination = \"D:\\\\Users\\\\Yani\\\\Desktop\\\\LoRa Rescue Data\\\\\"\n",
    "# Greg's Directory\n",
    "# save_destination = \"C:\\\\LoRa_Rescue\\\\\"\n",
    "\n",
    "# Change Current Working Directory in Python\n",
    "os.chdir(save_destination)\n",
    "\n",
    "# Arduino Configuration\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "port = \"COM9\"\n",
    "baud = 115200\n",
    "\n",
    "# Firebase Web App Configuration\n",
    "LoraRescueStorage = {'apiKey': \"AIzaSyAN2jdAfGBhbPz446Lho_Jmu2eysU6Hvqw\",\n",
    "    'authDomain': \"lora-rescue.firebaseapp.com\",\n",
    "    'databaseURL': \"https://lora-rescue-default-rtdb.asia-southeast1.firebasedatabase.app\",\n",
    "    'projectId': \"lora-rescue\",\n",
    "    'storageBucket': \"lora-rescue.appspot.com\",\n",
    "    'messagingSenderId': \"295122276311\",\n",
    "    'appId': \"1:295122276311:web:68ce5d4d4cd6763103c592\",\n",
    "    'measurementId': \"G-MCPTP8HPLK\"}\n",
    "\n",
    "# Read RawData.csv Configuration\n",
    "# In excel, the first row is treated as Row 0\n",
    "    # Basically, subtract 1 from excel row number\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "startrow = 1\n",
    "endrow = 58\n",
    "\n",
    "# RSSI to Distance calculation constants\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "n = 2.8\n",
    "dro = 1.5\n",
    "roRSSI = -32\n",
    "\n",
    "\n",
    "# Trilateration calculation constants\n",
    "# GNode GPS Coordinates\n",
    "# Format: A B C\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "latg = np.array([14.6648848,14.6648496,14.6648452])\n",
    "longg = np.array([120.9718980,120.9718835,120.9718860])\n",
    "\n",
    "# GNode Cartesian Coordinates\n",
    "# Format: A B C\n",
    "xg = np.array([0,0,0])\n",
    "yg = np.array([0,0,0])\n",
    "\n",
    "# Actual Mobile Node GPS Coordinates\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "latAct = np.array([14.6648547])\n",
    "longAct = np.array([120.9718816])\n",
    "\n",
    "# Actual Mobile Node Cartesian Coordinates\n",
    "xAct = np.array([0]) #Target x-coordinate\n",
    "yAct = np.array([0]) #Target y-coordinate\n",
    "\n",
    "################## CHANGE THIS ACCORDINGLY ##################\n",
    "# Circle Trilateration Points\n",
    "points = 100\n",
    "\n",
    "# Tolerance filter error margin\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "errorTolerance = 50\n",
    "\n",
    "# DBSCAN calculation constants\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "# Will be removed when an optimization function is made\n",
    "epsilon = 50\n",
    "minPts = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Declarations\n",
    "def listenForData(port,baud):\n",
    "    #Define variables for use\n",
    "    print(\"listening to port \"+str(port)+\" at \"+str(baud))\n",
    "    arduino = serial.Serial(port, baud)\n",
    "    rssiA = list()\n",
    "    rssiB = list()\n",
    "    rssiC = list()\n",
    "    phoneA = 0\n",
    "    phoneB = 0\n",
    "    phoneC = 0\n",
    "    okA = 0\n",
    "    okB = 0\n",
    "    okC = 0\n",
    "    ok = 0\n",
    "\n",
    "    while ok == 0: #will wait until ok is 1. 'ok' will only be 1 when A B C are matching.\n",
    "        arduino_raw_data = arduino.readline() #read serial data\n",
    "        decoded_data = str(arduino_raw_data.decode(\"utf-8\")) #convert to utf-8\n",
    "        data = decoded_data.replace('\\n','') #remove \\n in the decoded data\n",
    "        data = data.replace('\\r','')\n",
    "        gatewayID = data[:1] #get gateway ID\n",
    "        dataID = data[1:2] #get data ID\n",
    "        data = data[2:] #get data\n",
    "        if gatewayID == 'A':\n",
    "            if dataID == '1':\n",
    "                phoneA = data\n",
    "                print(\"\\nReceiving Gateway A: 0\" + phoneA)\n",
    "            elif dataID == '2':\n",
    "                rssiA.append(float(data))\n",
    "            elif dataID == '3':\n",
    "                timeA = str(dt.now())[0:19]\n",
    "                timeA = timeA.replace(':','-')\n",
    "                print(\"timeA: \" + timeA)\n",
    "                rssiA = np.delete(rssiA,len(rssiA)-1)\n",
    "                rssiA = np.delete(rssiA,len(rssiA)-1)\n",
    "                okA = 1\n",
    "        elif gatewayID == 'B':\n",
    "            if dataID == '1':\n",
    "                phoneB = data\n",
    "                print(\"\\nReceiving Gateway B: 0\" + phoneB)\n",
    "            elif dataID == '2':\n",
    "                rssiB.append(float(data))\n",
    "            elif dataID == '3':\n",
    "                timeB = str(dt.now())[0:19]\n",
    "                timeB = timeB.replace(':','-')\n",
    "                print(\"timeB: \" + timeB)\n",
    "                rssiB = np.delete(rssiB,len(rssiB)-1)\n",
    "                rssiB = np.delete(rssiB,len(rssiB)-1)\n",
    "                okB = 1\n",
    "        elif gatewayID == 'C':\n",
    "            if dataID == '1':\n",
    "                phoneC = data\n",
    "                print(\"\\nReceiving Gateway C: 0\" + phoneC)\n",
    "            if dataID == '2':\n",
    "                rssiC.append(float(data))\n",
    "            if dataID == '3':\n",
    "                timeC = str(dt.now())[0:19]\n",
    "                timeC = timeC.replace(':','-')\n",
    "                print(\"timeC: \" + timeC)\n",
    "                rssiC = np.delete(rssiC,len(rssiC)-1)\n",
    "                rssiC = np.delete(rssiC,len(rssiC)-1)\n",
    "                okC = 1\n",
    "        # Write to CSV, note if data matches\n",
    "        if phoneA == phoneB == phoneC and okA == 1 and okB == 1 and okC == 1:\n",
    "            with open(save_destination+'rawData.csv', mode='a') as logs:\n",
    "                logswrite = csv.writer(logs, dialect='excel', lineterminator='\\n')\n",
    "                logswrite.writerow(['Phone','Time','Gateway A','Gateway B','Gateway C'])\n",
    "                for i in range(len(rssiA)):\n",
    "                    logswrite.writerow([phoneA,timeA,rssiA[i],rssiB[i],rssiC[i]])\n",
    "            start_dt = dt.strptime(timeA[11:19], '%H-%M-%S')\n",
    "            end_dt = dt.strptime(timeC[11:19], '%H-%M-%S')\n",
    "            diff = abs(end_dt - start_dt)\n",
    "            print(\"\\nA, B, and C received successfully with interval of \"+str(diff))\n",
    "            ok = 1\n",
    "        elif okA == 1 and okB == 1 and okC == 1:\n",
    "            print(\"\\nError: Data mismatch, dumping date into error.csv\")\n",
    "            with open(save_destination+'error.csv', mode='a') as logs:\n",
    "                logswrite = csv.writer(logs, dialect='excel', lineterminator='\\n')\n",
    "                logswrite.writerow(['Time','Gateway A','Gateway B','Gateway C'])\n",
    "                for i in range(len(rssiA)):\n",
    "                    logswrite.writerow([phoneA,timeA,rssiA[i],rssiB[i],rssiC[i]])\n",
    "            rssiA = list()\n",
    "            rssiB = list()\n",
    "            rssiC = list()\n",
    "\n",
    "    return rssiA, rssiB, rssiC, timeA, phoneA #return the variables\n",
    "\n",
    "def serialListener(port,baud):\n",
    "    #Define variables for use\n",
    "    print(\"Listening to port \"+str(port)+\" at \"+str(baud))\n",
    "    arduino = serial.Serial(port, baud)\n",
    "    rssiA = list()\n",
    "    rssiB = list()\n",
    "    rssiC = list()\n",
    "    phoneA = 0\n",
    "    phoneB = 0\n",
    "    phoneC = 0\n",
    "    done= 0\n",
    "    ok = [0,0,0,0]\n",
    "    \n",
    "    while done == 0:\n",
    "        arduino_raw_data = arduino.readline()\n",
    "        decoded_data = str(arduino_raw_data.decode(\"utf-8\")) #convert to utf-8\n",
    "        rawData = decoded_data.replace('\\n','') #remove \\n in the decoded data\n",
    "        rawData = rawData.replace('\\r','')\n",
    "        gatewayID = rawData[:1] #get gateway ID\n",
    "        tempData = rawData[1:] #get data\n",
    "        dataSplit = list()\n",
    "        dataSplit = tempData.split()\n",
    "        phone = dataSplit[0]\n",
    "        rssi = dataSplit[1].replace(\"\\x00\",\"\")\n",
    "        rssiTemp = rssi\n",
    "        if not(rssiTemp.replace(\"-\",\"\").isnumeric()): continue\n",
    "        dtn = str(dt.now())\n",
    "        dtn = dtn[0:19]\n",
    "        dateNow = dtn[0:10]\n",
    "        timeNow = dtn[11:19]\n",
    "        print(dtn + \" Received Gateway \" + gatewayID + \": +63\" + phone + \" with RSSI: \" + rssi)\n",
    "\n",
    "        if gatewayID == 'A':\n",
    "            ok[0] = 1\n",
    "            phoneA = phone\n",
    "            temprssiA = rssi\n",
    "        elif gatewayID == 'B':\n",
    "            ok[1] = 1\n",
    "            phoneB = phone\n",
    "            temprssiB = rssi\n",
    "        elif gatewayID == 'C':\n",
    "            ok[2] = 1\n",
    "            phoneC = phone\n",
    "            temprssiC = rssi\n",
    "        else:\n",
    "            print(\"Unrecognized Serial Data: \" + rawData)\n",
    "\n",
    "        # Save to Database\n",
    "        firebase = pyrebase.initialize_app(LoraRescueStorage)\n",
    "        db = firebase.database()\n",
    "        if sum(ok) == 3 and phoneA == phoneB and phoneB == phoneC:\n",
    "            for i in range(3): ok[i] = 0\n",
    "            ok[3], timePrev = checkDatabase(dateNow,timeNow,phone)\n",
    "            timeNow = timePrev\n",
    "            rssiAlist = db.child(dateNow).child(timeNow).child(\"Raw RSSI Values\").child(\"RSSI Gateway A\").get().val()\n",
    "            if rssiAlist != None:\n",
    "                rssiAlist.append(temprssiA)\n",
    "            else:\n",
    "                rssiAlist = [temprssiA]\n",
    "            db.child(dateNow).child(timeNow).child(\"Raw RSSI Values\").child(\"RSSI Gateway A\").set(rssiAlist)\n",
    "            rssiBlist = db.child(dateNow).child(timeNow).child(\"Raw RSSI Values\").child(\"RSSI Gateway B\").get().val()\n",
    "            if rssiBlist != None:\n",
    "                rssiBlist.append(temprssiB)\n",
    "            else:\n",
    "                rssiBlist = [temprssiB]\n",
    "            db.child(dateNow).child(timeNow).child(\"Raw RSSI Values\").child(\"RSSI Gateway B\").set(rssiBlist)\n",
    "            rssiClist = db.child(dateNow).child(timeNow).child(\"Raw RSSI Values\").child(\"RSSI Gateway C\").get().val()\n",
    "            if rssiClist != None:\n",
    "                rssiClist.append(temprssiC)\n",
    "            else:\n",
    "                rssiClist = [temprssiC]\n",
    "            db.child(dateNow).child(timeNow).child(\"Raw RSSI Values\").child(\"RSSI Gateway C\").set(rssiClist)\n",
    "\n",
    "            if ok[3] == 1:\n",
    "                ok = [0,0,0,0]\n",
    "                done = 1\n",
    "            \n",
    "    # Write to CSV\n",
    "    databaseEntries = db.child(dateNow).child(timePrev).child(\"Raw RSSI Values\").get()\n",
    "    df = pd.read_json(json.dumps(list(databaseEntries.val().items())))\n",
    "    rssiA = df.iloc[0, 1]\n",
    "    rssiB = df.iloc[1, 1]\n",
    "    rssiC = df.iloc[2, 1]\n",
    "    dtn = dateNow + \" \" + timeNow\n",
    "    dtn = dtn.replace(':','-')\n",
    "    with open(save_destination+'rawData.csv', mode='a') as logs:\n",
    "        logswrite = csv.writer(logs, dialect='excel', lineterminator='\\n')\n",
    "        logswrite.writerow(['Phone','Time','Gateway A','Gateway B','Gateway C'])\n",
    "        for i in range(len(rssiA)):\n",
    "            logswrite.writerow([phone,dtn,rssiA[i],rssiB[i],rssiC[i]])\n",
    "    return rssiA, rssiB, rssiC, dtn, phone\n",
    "\n",
    "def checkDatabase(dateNow,timeNow,phone):\n",
    "    check = 0\n",
    "    timePrev = timeNow\n",
    "    n = 30 #This is range for time\n",
    "    firebase = pyrebase.initialize_app(LoraRescueStorage)\n",
    "    db = firebase.database()\n",
    "    databaseEntries = db.child(dateNow).get() #retreive the realtime database datapoints\n",
    "    if databaseEntries.val() == None:\n",
    "        check = 0\n",
    "        timePrev = timeNow + \" 0\" + phone\n",
    "        return check, timePrev\n",
    "    x = json.dumps(list(databaseEntries.val().items())) #convert ordered list to json\n",
    "    df = pd.read_json(x) #convert json to pandas dataframe for processing\n",
    "    entries = df.iloc[:, 0].tolist() #convert pandas dataframe to list of strings\n",
    "    for i in range(len(entries)):\n",
    "        checkDatePhone = entries[i].split()\n",
    "        if checkDatePhone[1] == \"0\"+phone:\n",
    "            tPrev = dt.strptime(checkDatePhone[0],'%H:%M:%S')\n",
    "            tNow = dt.strptime(timeNow,'%H:%M:%S') - td(minutes=n)\n",
    "            if tPrev > tNow:\n",
    "                timePrev = str(tPrev)[11:19]\n",
    "            else:\n",
    "                timePrev = timeNow\n",
    "    timePrev = timePrev + \" 0\" + phone\n",
    "    databaseEntries = db.child(dateNow).child(timePrev).child(\"Raw RSSI Values\").get()\n",
    "    if databaseEntries.val() == None:\n",
    "        check = 0\n",
    "        return check, timePrev\n",
    "    df = pd.read_json(json.dumps(list(databaseEntries.val().items())))\n",
    "    entries = df.iloc[0, 1]\n",
    "    print(dateNow + \" \" + timePrev + \" has \" + str(len(entries)) + \" entries\")\n",
    "    if len(entries) >= 50:\n",
    "        check = 1\n",
    "    return check, timePrev\n",
    "\n",
    "def importCSV(save_destination, startrow, endrow):\n",
    "    rawdataread = pd.read_csv(save_destination + 'rawData.csv', header=0)\n",
    "    #r\"\" specifies that it is a string. This is the location of the csv to be read\n",
    "    #header=0 means headers at row 0\n",
    "\n",
    "    rawdatalim = rawdataread[startrow-1:endrow-1] #limit for which columns to read.\n",
    "\n",
    "    phone = rawdatalim['Phone'].to_list()[0] #reads 1st column with Phone header\n",
    "    dtn  = rawdatalim['Time'].to_list()[0] #reads 1st column with Time header\n",
    "    rssiA = rawdatalim['Gateway A'].to_numpy(float) #reads column with Gateway A header and then converts into numpy float array\n",
    "    rssiB = rawdatalim['Gateway B'].to_numpy(float) #reads column with Gateway B header and then converts into numpy float array\n",
    "    rssiC = rawdatalim['Gateway C'].to_numpy(float) #reads column with Gateway C header and then converts into numpy float array\n",
    "    \n",
    "    return rssiA, rssiB, rssiC, dtn, phone\n",
    "\n",
    "def importDatabase(date, time, phone):\n",
    "    phoneTime = time + \" \" + phone\n",
    "    firebase = pyrebase.initialize_app(LoraRescueStorage)\n",
    "    db = firebase.database()\n",
    "    databaseEntries = db.child(date).child(phoneTime).child(\"Raw RSSI Values\").get()\n",
    "    df = pd.read_json(json.dumps(list(databaseEntries.val().items())))\n",
    "    rssiA = df.iloc[0, 1]\n",
    "    rssiB = df.iloc[1, 1]\n",
    "    rssiC = df.iloc[2, 1]\n",
    "    databaseEntries = db.child(date).child(phoneTime).child(\"Actual Data\").get()\n",
    "    df = pd.read_json(json.dumps(list(databaseEntries.val().items())))\n",
    "    mobileLatLong = df.iloc[1, 1].split()\n",
    "    latAct = np.array([float(mobileLatLong[0])])\n",
    "    longAct = np.array([float(mobileLatLong[1])])\n",
    "    latAct,longAct = cartToGPS(latAct,longAct)\n",
    "\n",
    "    databaseEntries = db.child(date).child(phoneTime).child(\"Basic Raw Information\").get()\n",
    "    df = pd.read_json(json.dumps(list(databaseEntries.val().items())))\n",
    "    gnodeA = df.iloc[3, 1].split()\n",
    "    gnodeB = df.iloc[4, 1].split()\n",
    "    gnodeC = df.iloc[5, 1].split()\n",
    "    dtn = date + \" \" + time\n",
    "    dtn = dtn.replace(':','-')\n",
    "    latg = np.array([float(gnodeA[0]),float(gnodeB[0]),float(gnodeC[0])])\n",
    "    longg = np.array([float(gnodeA[1]),float(gnodeB[1]),float(gnodeC[1])])\n",
    "    latg,longg = cartToGPS(latg,longg)\n",
    "    phone = phone[1:]\n",
    "    print('GNode Latitudes: ' + str(latg))\n",
    "    print('GNode Longitudes: '+ str(longg))\n",
    "    return rssiA, rssiB, rssiC, dtn, phone, latg, longg, latAct, longAct\n",
    "\n",
    "def rssiToDist(rssiA,rssiB,rssiC,n,dro,roRSSI):\n",
    "    distA = list()\n",
    "    distB = list()\n",
    "    distC = list()\n",
    "    rssi = [rssiA,rssiB,rssiC]\n",
    "    for i in range(len(rssi[0])):\n",
    "        distA.append(pow(10,((roRSSI-int(rssi[0][i]))/(10*n)))*dro)\n",
    "        distB.append(pow(10,((roRSSI-int(rssi[1][i]))/(10*n)))*dro)\n",
    "        distC.append(pow(10,((roRSSI-int(rssi[2][i]))/(10*n)))*dro)\n",
    "\n",
    "    return distA,distB,distC\n",
    "\n",
    "def drawCircle(xg,yg,rA,rB,rC,points):\n",
    "    intersect = [[0,[0,0]],[0,[0,0]],[0,[0,0]]]\n",
    "    r = [rA,rB,rC]\n",
    "    x = [[],[],[]]\n",
    "    y = [[],[],[]]\n",
    "    pi = 3.14\n",
    "    for i in range(3):\n",
    "        for j in range(points):\n",
    "            x[i].append(r[i]*cos(2*pi*j/points)+xg[i])\n",
    "            y[i].append(r[i]*sin(2*pi*j/points)+yg[i])\n",
    "    if (rA - rB)**2 <= (xg[0] - xg[1])**2 + (yg[0] - yg[1])**2 and (xg[0] - xg[1])**2 + (yg[0] - yg[1])**2 <= (rA + rB)**2:\n",
    "        xint, yint = get_intersections(xg[0], yg[0], rA, xg[1], yg[1], rB)\n",
    "        intersect[0] = [1,[xint,yint]]\n",
    "    if (rB - rC)**2 <= (xg[1] - xg[2])**2 + (yg[1] - yg[2])**2 and (xg[1] - xg[2])**2 + (yg[1] - yg[2])**2 <= (rB + rC)**2:\n",
    "        xint, yint = get_intersections(xg[1], yg[1], rB, xg[2], yg[2], rC)\n",
    "        intersect[1] = [1,[xint,yint]]\n",
    "    if (rA - rC)**2 <= (xg[0] - xg[2])**2 + (yg[0] - yg[2])**2 and (xg[0] - xg[2])**2 + (yg[0] - yg[2])**2 <= (rA + rC)**2:\n",
    "        xint, yint = get_intersections(xg[0], yg[0], rA, xg[2], yg[2], rC)\n",
    "        intersect[2] = [1,[xint,yint]]\n",
    "    return x,y,intersect\n",
    "\n",
    "def get_intersections(x0, y0, r0, x1, y1, r1):\n",
    "    # circle 1: (x0, y0), radius r0\n",
    "    # circle 2: (x1, y1), radius r1\n",
    "\n",
    "    d=sqrt((x1-x0)**2 + (y1-y0)**2)\n",
    "    # non intersecting\n",
    "    if d > r0 + r1 :\n",
    "        return None\n",
    "    # One circle within other\n",
    "    if d < abs(r0-r1):\n",
    "        return None\n",
    "    # coincident circles\n",
    "    if d == 0 and r0 == r1:\n",
    "        return None\n",
    "    else:\n",
    "        a=(r0**2-r1**2+d**2)/(2*d)\n",
    "        h=sqrt(r0**2-a**2)\n",
    "        x2=x0+a*(x1-x0)/d   \n",
    "        y2=y0+a*(y1-y0)/d   \n",
    "        x3=x2+h*(y1-y0)/d     \n",
    "        y3=y2-h*(x1-x0)/d \n",
    "        x4=x2-h*(y1-y0)/d\n",
    "        y4=y2+h*(x1-x0)/d\n",
    "        x = [x3,x4]\n",
    "        y = [y3,y4]\n",
    "        return x,y\n",
    "\n",
    "def trilaterateCircle(xCirc,yCirc,intersect,points):\n",
    "    deltaDist = [10000,10000,10000]\n",
    "    dist = [0,0,0]\n",
    "    x = [0,0,0]\n",
    "    y = [0,0,0]\n",
    "    for i in range(3):\n",
    "        for j in range(points):\n",
    "            for k in range(points):\n",
    "                if i <= 1:\n",
    "                    dist[i] = ((xCirc[i][j]-xCirc[i+1][k])**2)+((yCirc[i][j]-yCirc[i+1][k])**2)\n",
    "                    if dist[i] < deltaDist[i]:\n",
    "                        deltaDist[i] = dist[i]\n",
    "                        x[i] = (xCirc[i][j]+xCirc[i+1][k])/2\n",
    "                        y[i] = (yCirc[i][j]+yCirc[i+1][k])/2\n",
    "                elif i == 2:\n",
    "                    dist[i] = ((xCirc[i][j]-xCirc[0][k])**2)+((yCirc[i][j]-yCirc[0][k])**2)\n",
    "                    if dist[i] < deltaDist[i]:\n",
    "                        deltaDist[i] = dist[i]\n",
    "                        x[i] = (xCirc[i][j]+xCirc[0][k])/2\n",
    "                        y[i] = (yCirc[i][j]+yCirc[0][k])/2\n",
    "    for i in range(3):\n",
    "        if intersect[i][0] == 1 and i < 2:\n",
    "            dist1 = sqrt(((intersect[i][1][0][0]-x[2])**2)+((intersect[i][1][1][0]-y[2])**2))\n",
    "            dist2 = sqrt(((intersect[i][1][0][1]-x[2])**2)+((intersect[i][1][1][1]-y[2])**2))\n",
    "            if dist1 < dist2:\n",
    "                x[i] = intersect[i][1][0][0]\n",
    "                y[i] = intersect[i][1][1][0]\n",
    "            else:\n",
    "                x[i] = intersect[i][1][0][1]\n",
    "                y[i] = intersect[i][1][1][1]\n",
    "        elif intersect[i][0] == 1 and i == 2:\n",
    "            dist1 = sqrt(((intersect[i][1][0][0]-x[0])**2)+((intersect[i][1][1][0]-y[0])**2))\n",
    "            dist2 = sqrt(((intersect[i][1][0][1]-x[0])**2)+((intersect[i][1][1][1]-y[0])**2))\n",
    "            if dist1 < dist2:\n",
    "                x[i] = intersect[i][1][0][0]\n",
    "                y[i] = intersect[i][1][1][0]\n",
    "            else:\n",
    "                x[i] = intersect[i][1][0][1]\n",
    "                y[i] = intersect[i][1][1][1] \n",
    "    xTrilat = sum(x)/3\n",
    "    yTrilat = sum(y)/3\n",
    "    return xTrilat,yTrilat\n",
    "\n",
    "def tolFilter(x,y,errorTolerance):\n",
    "    i = 0\n",
    "    while i != 60:\n",
    "        if i == len(y):\n",
    "            i = 60\n",
    "            continue\n",
    "        e = 0\n",
    "        dist = np.sqrt(((xAve-x[i])**2)+((yAve-y[i])**2))\n",
    "        if dist >= errorTolerance:\n",
    "            #print(str(i)+\" - Deleted\"+' '+str(x[i])+' '+str(y[i]))\n",
    "            x = np.delete(x,i)\n",
    "            y = np.delete(y,i)\n",
    "        else:\n",
    "            #print(str(i)+' '+str(x[i])+' '+str(y[i]))\n",
    "            i += 1\n",
    "\n",
    "    return x,y\n",
    "\n",
    "def kmeansOptimize(data):\n",
    "    # Compute for inertias for every possible number of clusters\n",
    "    inertia = [] #aka Sum of Squared Distance Errors\n",
    "    for i in range(1,len(data)):\n",
    "        kmeans = KMeans(n_clusters=i).fit(data)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    #Determine optimal Number of Clusters based on Elbow\n",
    "    elbow = KneeLocator(range(1,len(data)),inertia, curve='convex', direction='decreasing')\n",
    "\n",
    "    #Perform K-means with elbow no. of clusters\n",
    "    kmeans = KMeans(n_clusters=elbow.knee, n_init=5).fit(data)\n",
    "\n",
    "    return kmeans,inertia,elbow\n",
    "\n",
    "def distanceFormula(x1, y1, x2, y2):\n",
    "    distance = np.sqrt(((x1-x2)**2)+((y1-y2)**2))\n",
    "\n",
    "    return distance\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    miles = 3959.87433\n",
    "    meters = 6372.8*1000\n",
    "\n",
    "    R = meters\n",
    "\n",
    "    dLat = radians(lat2 - lat1)\n",
    "    dLon = radians(lon2 - lon1)\n",
    "    lat1 = radians(lat1)\n",
    "    lat2 = radians(lat2)\n",
    "\n",
    "    a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n",
    "    c = 2*asin(sqrt(a))\n",
    "\n",
    "    distance = np.array([R*c])\n",
    "\n",
    "    return distance\n",
    "\n",
    "def GPSToCart(lat,lon):\n",
    "    # Convert GPS Coordinates to Cartesian Coordinates\n",
    "    # For manual checking, refer to https://epsg.io/transform#s_srs=4326&t_srs=25391 \n",
    "    # Defining CRS aka Coordinate Reference Systems\n",
    "    inCRS = CRS.from_epsg(4326) #CRS of GPS that uses Latitude and Longitude Values\n",
    "    outCRS = CRS.from_epsg(25391) #Luzon Datum of 1911 utilizing Transverse Mercator Project Map\n",
    "\n",
    "    #Conversion from GPS Coordinates to Philippine Cartesian Coordinates\n",
    "    GeoToCart = Transformer.from_crs(inCRS,outCRS)\n",
    "    x,y = GeoToCart.transform(lat,lon) #Format should be (lat,lon) for epsg:4326\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def cartToGPS(x,y):\n",
    "    # Convert Cartesian Coordinates back to GPS Coordinates\n",
    "    # For manual checking, refer to https://epsg.io/transform#s_srs=25391&t_srs=4326 \n",
    "    # Defining CRS aka Coordinate Reference Systems\n",
    "    inCRS = CRS.from_epsg(4326) #CRS of GPS that uses Latitude and Longitude Values\n",
    "    outCRS = CRS.from_epsg(25391) #Luzon Datum of 1911 utilizing Transverse Mercator Project Map\n",
    "\n",
    "    #Conversion from Philippine Cartesian back to GPS Coordinates Coordinates\n",
    "    CartToGeo = Transformer.from_crs(outCRS,inCRS)\n",
    "    lat, lon = CartToGeo.transform(x,y) #Format should be (x,y) for epsg:25391\n",
    "    lat = list(lat)\n",
    "    lon = list(lon)\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "def errorComp(x, y, xAct, yAct, kmeans, xAve, yAve, data):\n",
    "    compVact = list()\n",
    "    for i in range(len(x)):\n",
    "        compVact.append(np.sqrt((x[i]-xAct)**2+(y[i]-yAct)**2))\n",
    "\n",
    "    #K-means centroid vs. Average Point (dataset average)\n",
    "    centVave = np.sqrt((kmeans.cluster_centers_[:,0]-xAve)**2+(kmeans.cluster_centers_[:,1]-yAve)**2)\n",
    "\n",
    "    #Computed Position vs. K-means centroid\n",
    "    compVcent = np.sqrt([(data[:,0]-kmeans.cluster_centers_[0,0])**2+(data[:,1]-kmeans.cluster_centers_[0,1])**2])\n",
    "    for i in range(1,len(kmeans.cluster_centers_)):\n",
    "        distance = np.sqrt([(data[:,0]-kmeans.cluster_centers_[i,0])**2+(data[:,1]-kmeans.cluster_centers_[i,1])**2])\n",
    "        compVcent = np.append(compVcent,distance,axis=0)\n",
    "\n",
    "    return compVact, centVave, compVcent\n",
    "\n",
    "def firebaseUpload(firebaseConfig, localDir, cloudDir):\n",
    "    # Initialize Firebase Storage\n",
    "    firebase = pyrebase.initialize_app(firebaseConfig)\n",
    "    storage = firebase.storage()\n",
    "\n",
    "    # Upload files to Firebase Storage\n",
    "    storage.child(cloudDir).put(localDir)\n",
    "\n",
    "def dbscan(epsilon, minPts, data, fig):\n",
    "    db = DBSCAN(eps=epsilon, min_samples=minPts).fit(data)\n",
    "    dbData = data[db.labels_>-1] \n",
    "    dbLabels = db.labels_[db.labels_>-1]\n",
    "    dbGraph = plt.figure(fig)\n",
    "    plt.scatter(dbData[:,0],dbData[:,1], c=dbLabels, label = 'Mobile Node Clusters', cmap='brg', s=5)\n",
    "    plt.scatter(xg, yg, marker='1', label='GNode Locations', c='black', s=30)\n",
    "    plt.scatter(xAve, yAve, marker='^', label='Average Point', c='black', s=30)\n",
    "    plt.scatter(xAct, yAct, marker='*', label='Actual Point', c='green', s=30)\n",
    "    plt.scatter([], [], marker = ' ', label=' ') # Dummy Plots for Initial Parameters\n",
    "    plt.scatter([], [], marker=' ', label='Parameters: ')\n",
    "    plt.scatter([], [], marker=' ', label='n = '+str(n))\n",
    "    plt.scatter([], [], marker=' ', label='$D_{RSSIo} = $'+str(dro))\n",
    "    plt.scatter([], [], marker=' ', label='$RSSI_o = $'+str(roRSSI))\n",
    "    plt.scatter([], [], marker=' ', label='Circle Points = '+str(points))\n",
    "    plt.scatter([], [], marker=' ', label='ε  = '+str(epsilon))\n",
    "    plt.scatter([], [], marker=' ', label='MinPts  = '+str(minPts))\n",
    "    plt.grid(linewidth=1, color=\"w\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('gainsboro')\n",
    "    ax.set_axisbelow(True)\n",
    "    plt.xlabel('x-axis [Meters]')\n",
    "    plt.ylabel('y-axis [Meters]')\n",
    "    plt.title(dtn + ' 0' + phoneA  + ' DBSCAN', y=1.05)\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1.03)) \n",
    "    plt.savefig(save_destination + dtn + ' 0' + phoneA + ' DBSCAN.jpg', bbox_inches='tight') #Change Directory Accordingly\n",
    "    fig += 1\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen/Read for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen/Read for Data\n",
    "# Retrieve RSSI data, date and time, and phone number\n",
    "\n",
    "# Listen to COM port and check for errors\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "# rssiA, rssiB, rssiC, dtn, phoneA = listenForData(port,baud)\n",
    "# rssiA, rssiB, rssiC, dtn, phoneA = serialListener(port,baud)\n",
    "\n",
    "# Manually retrieve data from rawData.csv\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "# rssiA, rssiB, rssiC, dtn, phoneA = importCSV(save_destination, startrow, endrow)\n",
    "# Format Date: \"2021-10-30\" Time: \"14:46:14\" Phone: \"09976800632\"\n",
    "rssiA, rssiB, rssiC, dtn, phoneA, latg, longg, latAct, longAct =  importDatabase(\"2021-10-30\", \"14:46:14\", \"09976800632\")\n",
    "\n",
    "# Save RSSI values to Firebase Database\n",
    "# firebase = pyrebase.initialize_app(LoraRescueStorage)\n",
    "# db = firebase.database()\n",
    "# dataRSSI = {\"RSSI Gateway A\":list(rssiA),\n",
    "#     \"RSSI Gateway B\":list(rssiB),\n",
    "#     \"RSSI Gateway C\":list(rssiC)}\n",
    "# dtemp = dtn\n",
    "# db.child(dtemp.replace(\"-\",\":\")+' '+'0'+phoneA).child(\"Raw RSSI Values\").set(dataRSSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Conversion\n",
    "RSSI to Distance <br>\n",
    "GPS to Cartesian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RSSI to Distance\n",
    "distanceAf, distanceBf, distanceCf = rssiToDist(rssiA,rssiB,rssiC,n,dro,roRSSI)\n",
    "\n",
    "# Convert GPS Coordinates to Cartesian Coordinates\n",
    "xg,yg = GPSToCart(latg,longg)\n",
    "xAct,yAct = GPSToCart(latAct,longAct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trilateration Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trilateration Part of the Code\n",
    "for i in range(len(distanceAf)):\n",
    "    distanceAf[i] = float(distanceAf[i])\n",
    "    distanceBf[i] = float(distanceBf[i])\n",
    "    distanceCf[i] = float(distanceCf[i])\n",
    "# Convert Distances from each GNode to numpy arrays\n",
    "distanceAf = np.array(distanceAf)\n",
    "distanceBf = np.array(distanceBf)\n",
    "distanceCf = np.array(distanceCf)\n",
    "# Get average distances\n",
    "AfAve = sum(distanceAf)/len(distanceAf)\n",
    "BfAve = sum(distanceBf)/len(distanceBf)\n",
    "CfAve = sum(distanceCf)/len(distanceCf)\n",
    "# Rotate Graph, comment if not needed\n",
    "# xg, yg, xAct, yAct, notFlat = rotateGraph(xg, yg, xAct, yAct)\n",
    "\n",
    "# Trilaterate Data\n",
    "print(\"Trilaterating Data...\")\n",
    "# x,y = trilaterate(distanceAf,distanceBf,distanceCf,xg,yg)\n",
    "# xAve,yAve = trilaterate(AfAve,BfAve,CfAve,xg,yg)\n",
    "x = list()\n",
    "y = list()\n",
    "for i in range(len(distanceAf)):\n",
    "    distA = distanceAf[i]\n",
    "    distB = distanceBf[i]\n",
    "    distC = distanceCf[i]\n",
    "    xCirc, yCirc, intersect = drawCircle(xg,yg,distA,distB,distC,points)\n",
    "    xTrilat,yTrilat = trilaterateCircle(xCirc,yCirc,intersect,points)\n",
    "    x.append(xTrilat)\n",
    "    y.append(yTrilat)\n",
    "xCircAve, yCircAve, inter = drawCircle(xg,yg,AfAve,BfAve,CfAve,points)\n",
    "xAve,yAve = trilaterateCircle(xCircAve,yCircAve,inter,points)\n",
    "print(\"Done Trilaterating!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tolerance Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance Filter\n",
    "xFilt,yFilt = tolFilter(x,y,errorTolerance)\n",
    "\n",
    "# Disable Tolerance Filter\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "xFilt = x\n",
    "yFilt = y\n",
    "\n",
    "# Mean Coordinates after Tolerance Filter\n",
    "xFiltAve = np.mean(xFilt)\n",
    "yFiltAve = np.mean(yFilt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trilateration Graphs\n",
    "Frequency Distribution Graph <br>\n",
    "Distance Behavior Graph <br>\n",
    "Raw Trilateration Graph <br>\n",
    "Filtered Trilateration Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute actual distances of GNodes to mobile node\n",
    "################## CHANGE THIS ACCORDINGLY ##################  \n",
    "# Use distance formula\n",
    "# comp_distanceAf = distanceFormula(xAct, yAct, xg[0], yg[0])\n",
    "# comp_distanceBf = distanceFormula(xAct, yAct, xg[1], yg[1])\n",
    "# comp_distanceCf = distanceFormula(xAct, yAct, xg[2], yg[2])\n",
    "# Use haversine formula\n",
    "comp_distanceAf = haversine(latAct[0], longAct[0], latg[0], longg[0])\n",
    "comp_distanceBf = haversine(latAct[0], longAct[0], latg[1], longg[1])\n",
    "comp_distanceCf = haversine(latAct[0], longAct[0], latg[2], longg[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data frequency of the gateways\n",
    "fig = 1\n",
    "plt.figure(fig)\n",
    "distSeriesA = pd.Series(distanceAf).value_counts().reset_index().sort_values('index').reset_index(drop=True)\n",
    "distSeriesA.columns = ['Distance [Meters]','Frequency']\n",
    "distSeriesA['Distance [Meters]'] = distSeriesA['Distance [Meters]'].round()\n",
    "distSeriesB = pd.Series(distanceBf).value_counts().reset_index().sort_values('index').reset_index(drop=True)\n",
    "distSeriesB.columns = ['Distance [Meters]','Frequency']\n",
    "distSeriesB['Distance [Meters]'] = distSeriesB['Distance [Meters]'].round()\n",
    "distSeriesC = pd.Series(distanceCf).value_counts().reset_index().sort_values('index').reset_index(drop=True)\n",
    "distSeriesC.columns = ['Distance [Meters]','Frequency']\n",
    "distSeriesC['Distance [Meters]'] = distSeriesC['Distance [Meters]'].round()\n",
    "figur, axes = plt.subplots(1,3, figsize=(18, 5))\n",
    "axes[0].set_title(dtn + ' 0' + phoneA  + ' GNode A FD')\n",
    "plots = sns.barplot(ax=axes[0],x=\"Distance [Meters]\", y=\"Frequency\", data=distSeriesA)\n",
    "for bar in plots.patches:\n",
    "    plots.annotate(format(bar.get_height(), '.1f'), \n",
    "                    (bar.get_x() + bar.get_width() / 2, \n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                    size=9, xytext=(0, 8),\n",
    "                    textcoords='offset points')\n",
    "\n",
    "axes[1].set_title(dtn + ' 0' + phoneA  + ' GNode B FD')\n",
    "plots = sns.barplot(ax=axes[1],x=\"Distance [Meters]\", y=\"Frequency\", data=distSeriesB)\n",
    "for bar in plots.patches:\n",
    "    plots.annotate(format(bar.get_height(), '.1f'), \n",
    "                    (bar.get_x() + bar.get_width() / 2, \n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                    size=9, xytext=(0, 8),\n",
    "                    textcoords='offset points')\n",
    "\n",
    "axes[2].set_title(dtn + ' 0' + phoneA  + ' GNode C FD')\n",
    "plots = sns.barplot(ax=axes[2],x=\"Distance [Meters]\", y=\"Frequency\", data=distSeriesC)\n",
    "for bar in plots.patches:\n",
    "    plots.annotate(format(bar.get_height(), '.1f'), \n",
    "                    (bar.get_x() + bar.get_width() / 2, \n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                    size=9, xytext=(0, 8),\n",
    "                    textcoords='offset points')\n",
    "\n",
    "plt.savefig(save_destination + dtn + ' 0' + phoneA + ' FrequencyDistribution.jpg')\n",
    "fig += 1\n",
    "\n",
    "#For the .py file exclusively, the DB graph unexpectedly mixes with the FD graph without plt.close()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the behavior of the distance\n",
    "plt.figure(fig)\n",
    "plt.plot(distanceAf, 'r', label='GNode A Distances')\n",
    "plt.plot(distanceBf, 'g', label='GNode B Distances')\n",
    "plt.plot(distanceCf, 'b', label='GNode C Distances')\n",
    "plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*AfAve, 'r.', label='Average GNode A Distance')\n",
    "plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*BfAve, 'g.', label='Average GNode B Distance')\n",
    "plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*CfAve, 'b.', label='Average GNode C Distance')\n",
    "plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*comp_distanceAf, 'r--', label='Actual GNode A Distance')\n",
    "plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*comp_distanceBf, 'g--', label='Actual GNode B Distance')\n",
    "plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*comp_distanceCf, 'b--', label='Actual GNode C Distance')\n",
    "plt.plot([], [], ' ', label=' ') # Dummy Plots for Initial Parameters\n",
    "plt.plot([], [], ' ', label='Parameters:')\n",
    "plt.plot([], [], ' ', label='n = '+str(n))\n",
    "plt.plot([], [], ' ', label='$D_{RSSIo} = $'+str(dro))\n",
    "plt.plot([], [], ' ', label='$RSSI_o = $'+str(roRSSI))\n",
    "plt.title(dtn + ' 0' + phoneA  + ' Distance Behavior')\n",
    "plt.xlabel('Datapoint')\n",
    "plt.ylabel('Distance [Meters]')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1.03)) \n",
    "plt.savefig(save_destination + dtn + ' 0' + phoneA + ' DistanceBehavior.jpg', bbox_inches='tight')\n",
    "fig += 1\n",
    "\n",
    "# Plot the data for trilateration w/o the filters\n",
    "plt.figure(fig)\n",
    "plt.scatter(x, y, label='Mobile Node Locations', cmap='brg', s=20)\n",
    "plt.scatter(xAve, yAve, label='Average Mobile Node Locations', cmap='brg', s=20)\n",
    "plt.scatter(xg, yg, marker='1', label='GNode Locations', c='black', s=20)\n",
    "plt.scatter([], [], marker = ' ', label=' ') # Dummy Plots for Initial Parameters\n",
    "plt.scatter([], [], marker=' ', label='Parameters:')\n",
    "plt.scatter([], [], marker=' ', label='n = '+str(n))\n",
    "plt.scatter([], [], marker=' ', label='$D_{RSSIo} = $'+str(dro))\n",
    "plt.scatter([], [], marker=' ', label='$RSSI_o = $'+str(roRSSI))\n",
    "plt.scatter([], [], marker=' ', label='Circle Points = '+str(points))\n",
    "plt.grid(linewidth=1, color=\"w\")\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('gainsboro')\n",
    "ax.set_axisbelow(True)\n",
    "plt.title(dtn + ' 0' + phoneA  + ' Raw Trilateration', y=1.05)\n",
    "plt.xlabel('Longitude [Meters]')\n",
    "plt.ylabel('Latitude [Meters]')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1.03)) \n",
    "plt.savefig(save_destination + dtn + ' 0' + phoneA + ' RawTrilateration.jpg', bbox_inches='tight')\n",
    "fig += 1\n",
    "\n",
    "# Plot the data for trilateration w/ the filters\n",
    "plt.figure(fig)\n",
    "plt.scatter(xFilt, yFilt, label='Mobile Node Locations', cmap='brg', s=20)\n",
    "plt.scatter(xFiltAve, yFiltAve, label='Average Mobile Node Locations', cmap='brg', s=20)\n",
    "plt.scatter(xg, yg, marker='1', label='GNode Locations', c='black', s=20)\n",
    "plt.scatter([], [], marker = ' ', label=' ') # Dummy Plots for Initial Parameters\n",
    "plt.scatter([], [], marker=' ', label='Parameters:')\n",
    "plt.scatter([], [], marker=' ', label='n = '+str(n))\n",
    "plt.scatter([], [], marker=' ', label='$D_{RSSIo} = $'+str(dro))\n",
    "plt.scatter([], [], marker=' ', label='$RSSI_o = $'+str(roRSSI))\n",
    "plt.scatter([], [], marker=' ', label='Circle Points = '+str(points))\n",
    "plt.grid(linewidth=1, color=\"w\")\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('gainsboro')\n",
    "ax.set_axisbelow(True)\n",
    "plt.title(dtn + ' 0' + phoneA  + ' Filtered Trilateration', y=1.05)\n",
    "plt.xlabel('Longitude [Meters]')\n",
    "plt.ylabel('Latitude [Meters]')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1.03)) \n",
    "plt.savefig(save_destination + dtn + ' 0' + phoneA + ' FiltTrilateration.jpg', bbox_inches='tight')\n",
    "fig += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means\n",
    "print('Performing K-Means...')\n",
    "# K-means Clustering won't be performed if there is only 1 set of coordinates in the Dataset.\n",
    "if len(xFilt)<2:\n",
    "    print(\"K-means clustering can't be performed due to lack of sample coordinates\")\n",
    "    quit()\n",
    "\n",
    "# Create numpy array 'data' for K-means containing (xFilt,yFilt) coordinates\n",
    "data = np.array([[xFilt[0],yFilt[0]]])\n",
    "for i in range(1,len(xFilt)):\n",
    "    data = np.append(data,[[xFilt[i],yFilt[i]]], axis=0)\n",
    "\n",
    "# Mobile Node Duplicate Coordinates Filter for K-means Convergence\n",
    "data = np.unique(data, axis=0) #Eliminate Duplicates in data\n",
    "\n",
    "kmeans,inertia,elbow = kmeansOptimize(data)\n",
    "print('Optimal Number of Clusters is', elbow.knee)\n",
    "print('K-Means Done!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Graphs\n",
    "K-Means Elbow Graph <br>\n",
    "K-Means Graph <br>\n",
    "K-Means Folium Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Plot\n",
    "plt.figure(fig)\n",
    "plt.plot(range(1,len(data)), inertia)\n",
    "plt.plot([elbow.knee], inertia[elbow.knee-1], 'ro', label='Optimal Clusters: ' + str(elbow.knee))\n",
    "plt.plot([], [], ' ', label='@ SoSD: ' + str(\"{:.4f}\".format(inertia[elbow.knee-1])))\n",
    "plt.xlabel('No. of Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title(dtn + ' 0' + phoneA  + ' K-Means Elbow')\n",
    "plt.legend() \n",
    "plt.savefig(save_destination + dtn + ' 0' + phoneA + ' K-MeansElbow.jpg') #Change Directory Accordingly\n",
    "fig += 1\n",
    "\n",
    "# K-means Plot\n",
    "plt.figure(fig)\n",
    "plt.scatter(data[:,0],data[:,1], c=kmeans.labels_, label = 'Mobile Node Locations', cmap='brg', s=5)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], c=list(range(1,elbow.knee+1)), marker = 'x', label = 'Cluster Centers', cmap='brg', s=30)\n",
    "plt.scatter(xg, yg, marker='1', label='GNode Locations', c='black', s=30)\n",
    "plt.scatter(xAve, yAve, marker='^', label='Average Point', c='black', s=30)\n",
    "plt.scatter(xAct, yAct, marker='*', label='Actual Point', c='green', s=30)\n",
    "plt.scatter([], [], marker = ' ', label=' ') # Dummy Plots for Initial Parameters\n",
    "plt.scatter([], [], marker=' ', label='Parameters: ')\n",
    "plt.scatter([], [], marker=' ', label='n = '+str(n))\n",
    "plt.scatter([], [], marker=' ', label='$D_{RSSIo} = $'+str(dro))\n",
    "plt.scatter([], [], marker=' ', label='$RSSI_o = $'+str(roRSSI))\n",
    "plt.scatter([], [], marker=' ', label='Circle Points = '+str(points))\n",
    "plt.scatter([], [], marker=' ', label='No. of Clusters  = '+str(elbow.knee))\n",
    "plt.grid(linewidth=1, color=\"w\")\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('gainsboro')\n",
    "ax.set_axisbelow(True)\n",
    "plt.xlabel('Longitude [Meters]')\n",
    "plt.ylabel('Latitude [Meters]')\n",
    "plt.title(dtn + ' 0' + phoneA  + ' K-Means', y=1.05)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1.03)) \n",
    "plt.savefig(save_destination + dtn + ' 0' + phoneA + ' K-Means.jpg', bbox_inches='tight') #Change Directory Accordingly\n",
    "fig += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Plot Folium Mapping\n",
    "# Cartesian to GPS Coordinate Conversion\n",
    "latData, longData = cartToGPS(data[:,0],data[:,1])\n",
    "latCenter, longCenter = cartToGPS(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1])\n",
    "latAve, longAve = cartToGPS(np.array([xAve]), np.array([yAve]))\n",
    "latAct, longAct = cartToGPS(xAct, yAct)\n",
    "\n",
    "# Establish Folium Map\n",
    "m = folium.Map(location=[latg[0], longg[0]], zoom_start=20)\n",
    "\n",
    "# Add Mobile Node Locations to Folium Map\n",
    "for i in range(len(latData)):\n",
    "    folium.Circle(\n",
    "        radius=1,\n",
    "        location=[latData[i], longData[i]],\n",
    "        tooltip='Mobile Node Locations',\n",
    "        popup=str(latData[i])+','+str(longData[i]),\n",
    "        color='red',\n",
    "        fill='True'\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add Cluster Centers\n",
    "for i in range(len(latCenter)):\n",
    "    folium.Circle(\n",
    "        radius=1,\n",
    "        location=[latCenter[i], longCenter[i]],\n",
    "        tooltip='Cluster Centers',\n",
    "        popup=str(latCenter[i])+','+str(longCenter[i]),\n",
    "        color='blue',\n",
    "        fill='True'\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add GNode Locations\n",
    "for i in range(len(latg)):\n",
    "    folium.Marker(\n",
    "        location=[latg[i], longg[i]],\n",
    "        tooltip='GNode Locations',\n",
    "        popup=str(latg[i])+','+str(longg[i]),\n",
    "        icon=folium.Icon(color='black', icon='hdd-o', prefix='fa'),\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add Average Points\n",
    "folium.Circle(\n",
    "    radius=1,\n",
    "    location=[latAve[0], longAve[0]],\n",
    "    tooltip='Average Point',\n",
    "    popup=str(latAve[0])+','+str(longAve[0]),\n",
    "    color='black',\n",
    "    fill='True'\n",
    ").add_to(m)\n",
    "\n",
    "# Save HTML Map File\n",
    "m.save(save_destination + dtn + ' 0' + phoneA + ' FoliumMapping.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "print('Performing DBSCAN...')\n",
    "# Create numpy array 'dataDB' for DBSCAN containing (x,y) coordinates\n",
    "dataDB = np.array([[x[0],y[0]]])\n",
    "for i in range(1,len(xFilt)):\n",
    "    dataDB = np.append(dataDB,[[x[i],y[i]]], axis=0)\n",
    "fig = dbscan(epsilon, minPts, dataDB, fig)\n",
    "print('DBSCAN Done!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Computations\n",
    "# Computed Position vs. Actual Position\n",
    "compVact, centVave, compVcent = errorComp(x, y, xAct, yAct, kmeans, xAve, yAve, data)\n",
    "compVactAve = sum(compVact)/len(compVact)\n",
    "\n",
    "# Plot the behavior of the error\n",
    "plt.figure(fig)\n",
    "plt.plot(compVact, 'r', label='Trilateration Error')\n",
    "plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*compVactAve , 'r--', label='Average Error')\n",
    "# plt.plot(np.arange(len(distanceAf)),np.ones([1,len(distanceAf)])[0]*comp_distanceAf, 'r--', label='Actual GNode A Distance')\n",
    "plt.plot([], [], ' ', label=' ') # Dummy Plots for Initial Parameters\n",
    "plt.plot([], [], ' ', label='Parameters:')\n",
    "plt.plot([], [], ' ', label='n = '+str(n))\n",
    "plt.plot([], [], ' ', label='$D_{RSSIo} = $'+str(dro))\n",
    "plt.plot([], [], ' ', label='$RSSI_o = $'+str(roRSSI))\n",
    "plt.title(dtn + ' 0' + phoneA  + ' Error Behavior')\n",
    "plt.xlabel('Datapoint')\n",
    "plt.ylabel('Distance [Meters]')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1.03)) \n",
    "plt.savefig(save_destination + dtn + ' 0' + phoneA + ' ErrorBehavior.jpg', bbox_inches='tight')\n",
    "fig += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Logging\n",
    "CSV Writing <br>\n",
    "Firebase Realtime Database <br>\n",
    "Firebase Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Writing\n",
    "print('Saving to CSV...')\n",
    "with open(save_destination+'Basic.csv', mode='a') as blogs:\n",
    "    blogswrite = csv.writer(blogs, dialect='excel', lineterminator='\\n')\n",
    "    blogswrite.writerow(['Time',dtn])\n",
    "    blogswrite.writerow(['Phone#','0'+phoneA])\n",
    "    blogswrite.writerow(['gnodeA',np.append(xg[0],yg[0])])\n",
    "    blogswrite.writerow(['gnodeB',np.append(xg[1],yg[1])])\n",
    "    blogswrite.writerow(['gnodeC',np.append(xg[2],yg[2])])\n",
    "    blogswrite.writerow(['Mean Raw Distances'])\n",
    "    blogswrite.writerow(['A','B','C'])\n",
    "    blogswrite.writerow([AfAve,BfAve,CfAve])\n",
    "    blogswrite.writerow(['Mean Raw X and Y Coordinates','','','',np.append(xAve,yAve)])\n",
    "    blogswrite.writerow(['Mean Coordinates with Tolerance Filter','','','',np.append(xFiltAve,yFiltAve)])\n",
    "    blogswrite.writerow(['Optimal # of Clusters','',elbow.knee])\n",
    "    blogswrite.writerow([''])\n",
    "    blogswrite.writerow([''])\n",
    "    \n",
    "with open(save_destination+'DistanceConstants.csv', mode='a') as blogs:\n",
    "    blogswrite = csv.writer(blogs, dialect='excel', lineterminator='\\n')\n",
    "    blogswrite.writerow(['Time',dtn])\n",
    "    blogswrite.writerow(['Phone#','0'+phoneA])\n",
    "    blogswrite.writerow(['n',n])\n",
    "    blogswrite.writerow(['dro',dro])\n",
    "    blogswrite.writerow(['RO RSSI',roRSSI])\n",
    "    blogswrite.writerow(['Circumference Points',points])\n",
    "    blogswrite.writerow([''])\n",
    "    blogswrite.writerow([''])\n",
    "    \n",
    "with open(save_destination+'Actual.csv', mode='a') as alogs:\n",
    "    alogswrite = csv.writer(alogs, dialect='excel', lineterminator='\\n')\n",
    "    alogswrite.writerow(['Time',dtn])\n",
    "    alogswrite.writerow(['Phone#','0'+phoneA])\n",
    "    alogswrite.writerow(['Actual Coordinates','',np.append(xAct,yAct)])\n",
    "    alogswrite.writerow(['Actual Computed Distances from Gnodes'])\n",
    "    alogswrite.writerow(['A','','B','','C'])\n",
    "    alogswrite.writerow([comp_distanceAf,'',comp_distanceBf,'',comp_distanceCf])\n",
    "    alogswrite.writerow(['Trilateration Error vs Actual Coordinates'])\n",
    "    for i in range(np.shape(compVact)[0]):\n",
    "        alogswrite.writerow([compVact[i]])\n",
    "    alogswrite.writerow([''])\n",
    "    alogswrite.writerow([''])\n",
    "\n",
    "with open(save_destination+'Coordinates.csv', mode='a') as clogs:\n",
    "    clogswrite = csv.writer(clogs, dialect='excel', lineterminator='\\n')\n",
    "    clogswrite.writerow(['Time',dtn])\n",
    "    clogswrite.writerow(['Phone#','0'+phoneA])\n",
    "    clogswrite.writerow(['Raw X and Y Coordinates'])\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        clogswrite.writerow([np.append(x[i],y[i])])\n",
    "    clogswrite.writerow(['-------------------------------'])\n",
    "    clogswrite.writerow(['Coordinates with Tolerance Filter'])\n",
    "    for i in range(np.shape(xFilt)[0]):\n",
    "        clogswrite.writerow([np.append(xFilt[i],yFilt[i])])\n",
    "    clogswrite.writerow([''])\n",
    "    clogswrite.writerow([''])\n",
    "    \n",
    "with open(save_destination+'Distances.csv', mode='a') as dlogs:\n",
    "    dlogswrite = csv.writer(dlogs, dialect='excel', lineterminator='\\n')\n",
    "    dlogswrite.writerow(['Time',dtn])\n",
    "    dlogswrite.writerow(['Phone#','0'+phoneA])\n",
    "    dlogswrite.writerow(['Raw Distances'])\n",
    "    dlogswrite.writerow(['A','B','C'])\n",
    "    for i in range(len(distanceAf)):\n",
    "        dlogswrite.writerow([distanceAf[i],distanceBf[i],distanceCf[i]])    \n",
    "    dlogswrite.writerow([''])\n",
    "    dlogswrite.writerow([''])\n",
    "    \n",
    "    with open(save_destination+'K-Means.csv', mode='a') as klogs:\n",
    "        klogswrite = csv.writer(klogs, dialect='excel', lineterminator='\\n')\n",
    "        klogswrite.writerow(['Time',dtn])\n",
    "        klogswrite.writerow(['Phone#','0'+phoneA])\n",
    "        klogswrite.writerow(['Inertia'])\n",
    "        for i in range(len(inertia)):\n",
    "            klogswrite.writerow([inertia[i]]) \n",
    "        klogswrite.writerow(['K-Means Centroid Coordinates'])\n",
    "        for i in range(elbow.knee):\n",
    "            klogswrite.writerows([[np.append(kmeans.cluster_centers_[i,0],kmeans.cluster_centers_[i,1])]]) \n",
    "        klogswrite.writerow(['K-Means Centroids vs. Mean Coordinates with Tolerance Filter'])\n",
    "        klogswrite.writerows([centVave])\n",
    "        klogswrite.writerow(['K-Means Centroids vs. Coordinates w/ Tolerance Filter '])\n",
    "        for i in range(len(compVcent)):    \n",
    "            for j in range (len(compVcent[i])):\n",
    "                klogswrite.writerow([compVcent[i][j]])\n",
    "            klogswrite.writerow(['-------------------------------'])\n",
    "        klogswrite.writerow([''])\n",
    "        klogswrite.writerow([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firebase Realtime Database\n",
    "print('Uploading to LoRa Rescue Realtime Database...')\n",
    "firebase = pyrebase.initialize_app(LoraRescueStorage)\n",
    "db = firebase.database()\n",
    "dataBasic = {\"GNode A\":' '.join([str(item) for item in list(np.append(xg[0],yg[0]))]),\n",
    "        \"GNode B\":' '.join([str(item) for item in list(np.append(xg[1],yg[1]))]),\n",
    "        \"GNode C\":' '.join([str(item) for item in list(np.append(xg[2],yg[2]))]),\n",
    "        \"Distance A Mean\":AfAve,\"Distance B Mean\":BfAve,\"Distance C Mean\":CfAve,\n",
    "        \"Mean X and Y Coordinates\":' '.join([str(item) for item in list(np.append(xAve,yAve))]),\n",
    "        \"Mean Filtered X and Y Coordinates\":' '.join([str(item) for item in list(np.append(xFiltAve,yFiltAve))]),\n",
    "        \"Optimal Number of Clusters\":int(elbow.knee)}\n",
    "dataActual = {\"Actual Coordinates\":' '.join([str(item).replace(\"[\",\"\").replace(\"]\",\"\") for item in list(np.append(xAct,yAct))]),\n",
    "        \"Actual Computed Distances from Gnodes (A B C)\":str(comp_distanceAf).replace(\"[\",\"\").replace(\"]\",\"\")+\" \"+str(comp_distanceBf).replace(\"[\",\"\").replace(\"]\",\"\")+\" \"+str(comp_distanceCf).replace(\"[\",\"\").replace(\"]\",\"\"),\n",
    "        \"Trilateration Error vs Actual Coordinates\":[str(item).replace(\"[\",\"\").replace(\"]\",\"\") for item in compVact]}\n",
    "dataCoordinates = {\"Raw X\":list(x), \"Raw Y\":list(y),\n",
    "        \"Filtered X\":list(xFilt), \"Filtered Y\":list(yFilt)}\n",
    "dataDistances = {\"Distance to GNode A\":list(distanceAf),\n",
    "        \"Distance to GNode B\":list(distanceBf),\n",
    "        \"Distance to GNode C\":list(distanceCf)}\n",
    "dataDistanceCalc = {\"n\":n,\n",
    "        \"dro\":dro,\n",
    "        \"roRSSI\":roRSSI,\n",
    "        \"Circumference Points\":points}\n",
    "\n",
    "clusterCenterX = list()\n",
    "clusterCenterY = list()\n",
    "clusterCompVcent = list()\n",
    "for i in range(elbow.knee):\n",
    "        clusterCenterX.append(''.join([str(item) for item in list(str(kmeans.cluster_centers_[i,0]))]))\n",
    "        clusterCenterY.append(''.join([str(item) for item in list(str(kmeans.cluster_centers_[i,1]))]))\n",
    "for i in range(len(compVcent)):    \n",
    "        for j in range (len(compVcent[i])):\n",
    "                clusterCompVcent.append(compVcent[i][j])\n",
    "\n",
    "dataKmeans = {\"Intertia\":list(inertia),\n",
    "        \"Centroid X\":list(clusterCenterX),\n",
    "        \"Centroid Y\":list(clusterCenterY),\n",
    "        \"Centroids vs Mean Coordinates w Tolerance Filter\":list(centVave),\n",
    "        \"Centroids vs Coordinates w Tolerance Filter\":list(clusterCompVcent)}\n",
    "\n",
    "dateAndTime = dtn.split()\n",
    "dateNow = dateAndTime[0]\n",
    "timeNow = dateAndTime[1].replace(\"-\",\":\")\n",
    "db.child(dateNow).child(timeNow +' 0'+phoneA).child(\"Basic Raw Information\").set(dataBasic)\n",
    "db.child(dateNow).child(timeNow +' 0'+phoneA).child(\"Distance Calculation Constants\").set(dataDistanceCalc)\n",
    "db.child(dateNow).child(timeNow +' 0'+phoneA).child(\"Actual Data\").set(dataActual)\n",
    "db.child(dateNow).child(timeNow +' 0'+phoneA).child(\"Raw and Filtered Coordinates\").set(dataCoordinates)\n",
    "db.child(dateNow).child(timeNow +' 0'+phoneA).child(\"Distances to Gateway Nodes\").set(dataDistances)\n",
    "db.child(dateNow).child(timeNow +' 0'+phoneA).child(\"Kmeans Data\").set(dataKmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firebase Storage\n",
    "print('Uploading to LoRa Rescue Storage...\\n')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' FrequencyDistribution.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Distance/FrequencyDistribution.jpg')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' DistanceBehavior.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Distance/DistanceBehavior.jpg')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' ErrorBehavior.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Trilateration/ErrorBehavior.jpg')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' RawTrilateration.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Trilateration/RawTrilateration.jpg')    \n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' FiltTrilateration.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Trilateration/FiltTrilateration.jpg')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' K-MeansElbow.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Clustering/K-MeansElbow.jpg')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' K-Means.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Clustering/K-Means.jpg')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' FoliumMapping.html',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Trilateration/FoliumMapping.html')\n",
    "firebaseUpload(LoraRescueStorage, \n",
    "    dtn + ' 0' + phoneA + ' DBSCAN.jpg',\n",
    "    'LoRa Rescue Data/' + dtn[0:10] + '/' + dtn[11:19].replace(\"-\",\":\") + ' 0' + phoneA + '/Clustering/DBSCAN.jpg')\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f64f3231b1e311572a0b8c39c3c368f9f5176ce3f5574c6f706e27bff92d772c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
